# -*- coding: utf-8 -*-
"""logisticregression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KwfvUXt9KoZSGQaC3JgzzizSu9sFiSIt
"""

from google.colab import files

uploaded = files.upload()

import io
import pandas as pd

headlines_data = pd.read_csv(io.BytesIO(uploaded['realcountriesdata - realcountriesdata.csv']))

headlines_data = headlines_data.drop(index = headlines_data.index[:200])

headlines_data = headlines_data[:-400]

headlines_data

import nltk
nltk.download('stopwords')

from nltk.corpus import stopwords
stop = stopwords.words('english')

headlines_data['headline_text'] = headlines_data['headline_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))

nltk.download('punkt')

headlines_data["tokenized_sents"] = headlines_data.apply(lambda row: set(nltk.word_tokenize(row['headline_text'])), axis = 1)

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

X_train, X_test, y_train, y_test = train_test_split(headlines_data['tokenized_sents'], headlines_data['label'], test_size=0.2, random_state=42)

#Convert the tokenized collection of lists to a list of strings
X_train_strings = [' '.join(tokens) for tokens in X_train]
X_test_strings = [' '.join(tokens) for tokens in X_test]

#vectorizing, fitting, and transforming
vectorizer = CountVectorizer()
X_train_vec = vectorizer.fit_transform(X_train_strings)
X_test_vec = vectorizer.transform(X_test_strings)

#logreg
logreg = LogisticRegression()
logreg.fit(X_train_vec, y_train)

#prediction
y_pred = logreg.predict(X_test_vec)

from sklearn.metrics import accuracy_score, confusion_matrix

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

confusion = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(confusion)

from sklearn.metrics import classification_report

report = classification_report(y_test, y_pred)

print("Classification Report:")
print(report)

test = files.upload()

comparison_data = pd.read_csv(io.BytesIO(test['countries_headlines-3 - Sheet1.csv']))

comparison_data_vector = vectorizer.transform(comparison_data["tokenized_sents"])
predictions = logreg.predict(comparison_data_vector)

comparison_data['label'] = predictions

comparison_data.to_csv('comparison_data.csv',index = False)
files.download('comparison_data.csv')