# -*- coding: utf-8 -*-
"""prepocessingAndImplementing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-CfLXI8k1n9shDezypZoX78fh8PNYSp8
"""

#uploading csv file
from google.colab import files

uploaded = files.upload()

#making the dataframe
import io
import pandas as pd

headlines_data = pd.read_csv(io.BytesIO(uploaded['updatedheadlines (1).csv']))
del headlines_data["publish_date"]

#Labeling every headline as either positive or negative or neutral

import nltk
nltk.download("vader_lexicon")
from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA

sia = SIA()
results = []

for sentence in headlines_data['headline_text']:
  polarity_scores = sia.polarity_scores(sentence)
  if polarity_scores['compound'] > 0.2:
    results.append(1)
  elif(polarity_scores['compound']< -0.2):
    results.append(-1)
  else:
    results.append(0)

headlines_data['label'] = results
headlines_data.head(20)

headlines_data = headlines_data[2000:]

headlines_data = headlines_data[:2000]

headlines_data



for i in range(2000,4000):
  if headlines_data['label'][i] == -1:
    headlines_data['label'][i] = 0
  elif headlines_data['label'][i] == 0:
    headlines_data['label'][i] = 1
  else:
    headlines_data['label'][i] = 2
headlines_data

headlines_data.to_csv('bertTestData.csv', index = False)

files.download('bertTestData.csv')

#Plot counting how many negative/positive/neutral are in the dataset
import matplotlib.pyplot as plt
import seaborn as sns


#sns.set(style='darkgrid', context='talk', palette='Dark2')

#fig, ax = plt.subplots(figsize=(8, 8))

#counts = headlines_data.label.value_counts(normalize=True) * 100

#sns.barplot(x=counts.index, y=counts, ax=ax)

#ax.set_xticklabels(['Negative', 'Neutral', 'Positive'])
#ax.set_ylabel("Percentage")

#plt.show()

#downloading stopwords
import nltk
nltk.download('stopwords')

#removing stopwords

from nltk.corpus import stopwords
stop = stopwords.words('english')

headlines_data['headline_text'] = headlines_data['headline_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))

#dowloading for the tokenizing
nltk.download('punkt')

#tokenizing
headlines_data["tokenized_sents"] = headlines_data.apply(lambda row: set(nltk.word_tokenize(row['headline_text'])), axis = 1)

# list of developing and developed countries

#list of the 152 developing countries as defined by the IMF
developing_countries = set([
    "afghanistan", "albania", "algeria", "angola", "antigua and barbuda",
    "argentina", "armenia", "azerbaijan", "bangladesh", "barbados",
    "belarus", "belize", "benin", "bhutan", "bolivia", "bosnia and herzegovina",
    "botswana", "brazil", "burkina faso", "burundi", "cabo verde", "cambodia",
    "cameroon", "central african republic", "chad", "colombia", "comoros",
    "congo, democratic republic of the", "congo, republic of the", "costa rica",
    "cote d'ivoire", "cuba", "djibouti", "dominica", "dominican republic",
    "ecuador", "egypt", "el salvador", "eritrea", "eswatini (swaziland)", "ethiopia",
    "fiji", "gabon", "gambia", "georgia", "ghana", "grenada", "guatemala", "guinea",
    "guinea-bissau", "guyana", "haiti", "honduras", "india", "indonesia", "iran",
    "iraq", "jamaica", "jordan", "kazakhstan", "kenya", "kiribati", "kosovo",
    "kyrgyzstan", "laos", "lebanon", "lesotho", "liberia", "libya", "madagascar",
    "malawi", "malaysia", "maldives", "mali", "marshall islands", "mauritania",
    "mauritius", "mexico", "micronesia", "moldova", "mongolia", "montenegro",
    "morocco", "mozambique", "myanmar", "burma", "namibia", "nauru", "nepal",
    "nicaragua", "niger", "nigeria", "north korea", "north macedonia", "pakistan",
    "palau", "panama", "papua new guinea", "paraguay", "peru", "philippines",
    "rwanda", "saint kitts and nevis", "saint lucia", "saint vincent and the grenadines",
    "samoa", "sao tome and principe", "senegal", "serbia", "seychelles",
    "sierra leone", "solomon islands", "somalia", "south africa", "south sudan",
    "sri lanka", "sudan", "suriname", "syria", "tajikistan", "tanzania", "thailand",
    "timor-leste", "togo", "tonga", "tunisia", "turkey", "turkmenistan", "tuvalu",
    "uganda", "ukraine", "uzbekistan", "vanuatu", "venezuela", "vietnam", "yemen",
    "zambia", "zimbabwe"
])

#list of the top 30 developed countries by the IMF. Some abbreviations are there for countries with common abbreviations.
developed_countries = set([
    "norway", "switzerland", "ireland", "germany", "china",
    "australia", "iceland", "sweden", "singapore", "netherlands", "denmark",
    "finland", "canada", "new zealand", "nz", "united kingdom","uk", "belgium", "liechtenstein",
    "united states", "us", "japan", "austria", "luxembourg", "israel", "south korea",
    "france", "slovenia", "spain", "italy", "czech republic", "malta", "estonia", "aust", "british", "briton", "britain"
])

#finding out if the country is in the row
headlines_data['developed_exists'] = headlines_data.apply(lambda row: 1 if len(row['tokenized_sents'] & developed_countries) > 0 else 0, axis = 1)
headlines_data['developing_exists'] = headlines_data.apply(lambda row: 1 if len(row['tokenized_sents'] & developing_countries) > 0 else 0, axis = 1)
headlines_data['cat'] = headlines_data.apply(lambda row: 'developed' if row['developed_exists'] == 1 else 'none', axis=1)
headlines_data['cat'] = headlines_data.apply(lambda row: 'developing' if (row['developing_exists'] == 1 and row['cat'] != 'developed') else row['cat'], axis=1)
headlines_data['cat'] = headlines_data.apply(lambda row: 'developed/developing' if row['developing_exists'] == 1 and row['cat'] == 'developed' else row['cat'], axis = 1)


headlines_data

num_developed = [x for x in headlines_data['cat'] if x == 'developed']
print(len(num_developed))
num_developing = [x for x in headlines_data['cat'] if x == 'developing']
print(len(num_developing))
num_developing_developed = [x for x in headlines_data['cat'] if x == 'developed/developing']
print(len(num_developing_developed))

headlines_data.shape

#graph that needs -1 label on the x axis and #developed_exists and #developing_exists on the y-axis
#sns.set(style='darkgrid', context='talk', palette='Dark2')

#fig, ax = plt.subplots(figsize=(8, 8))
#sns.barplot(x=headlines_data['label'], y= headlines_data['developed_exists'], ax=ax)

#ax.set_xticklabels(["-1","0","1"])
#ax.set_ylabel("Developed")

#plt.show()

#sns.set(style='darkgrid', context='talk', palette='Dark2')

#fig, ax = plt.subplots(figsize=(8, 8))
#sns.barplot(x=headlines_data['label'], y= headlines_data['developing_exists'], ax=ax)

#ax.set_xticklabels(["-1","0","1"])
#ax.set_ylabel("Developing")

#plt.show()

#Vectorizing and logistic regression
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

X_train, X_test, y_train, y_test = train_test_split(headlines_data['tokenized_sents'], headlines_data['label'], test_size=0.2, random_state=42)

#Convert the tokenized collection of lists to a list of strings
X_train_strings = [' '.join(tokens) for tokens in X_train]
X_test_strings = [' '.join(tokens) for tokens in X_test]

#vectorizing, fitting, and transforming
vectorizer = CountVectorizer()
X_train_vec = vectorizer.fit_transform(X_train_strings)
X_test_vec = vectorizer.transform(X_test_strings)

#logreg
logreg = LogisticRegression()
logreg.fit(X_train_vec, y_train)

#prediction
y_pred = logreg.predict(X_test_vec)

#accuracy and confusion matrix

from sklearn.metrics import accuracy_score, confusion_matrix

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

confusion = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(confusion)

#Recall and precision
from sklearn.metrics import classification_report

report = classification_report(y_test, y_pred)

print("Classification Report:")
print(report)

import numpy as np

#creates a new dataframe with only data with countries in it

countries_data = headlines_data.loc[headlines_data['cat'] != 'none']
countries_data.shape

countries_data.to_csv('bertPredictThis.csv', index = False)

files.download('bertPredictThis.csv')

import csv
from google.colab import files
import pandas as pd
import io

csv_file_path = 'countries_headlines.csv'

countries_data1 = countries_data.iloc[:400]


countries_data1.to_csv(csv_file_path, index = False)

files.download(csv_file_path)

#graphs the # of positive, negative, and neutral in the countries_data
# i think we might have to create individual dataframes of developed, developing, and both and then go from there to graph everything in the same plot

negative_labels = [0,0,0]
neutral_labels = [0,0,0]
positive_labels = [0,0,0]

developing_data = countries_data.loc[countries_data['cat'] == 'developing']
developed_data = countries_data.loc[countries_data['cat'] == 'developed']
both_data =countries_data.loc[countries_data['cat'] == 'developed/developing']

#get the number of -1,0,and 1 in each

negative_labels[0] = len([x for x in developing_data['label'] if x == -1])
negative_labels[1] = len([x for x in developed_data['label'] if x == -1])
negative_labels[2] = len([x for x in both_data['label'] if x == -1])

neutral_labels[0] = len([x for x in developing_data['label'] if x == 0])
neutral_labels[1] = len([x for x in developed_data['label'] if x == 0])
neutral_labels[2] = len([x for x in both_data['label'] if x ==0])


positive_labels[0] = len([x for x in developing_data['label'] if x == 1])
positive_labels[1] = len([x for x in developed_data['label'] if x == 1])
positive_labels[2] = len([x for x in both_data['label'] if x == 1])

categories = ['developing','developed','developed/developing']

#actual graphing portion
bar_width = 0.2
index = np.arange(len(categories))
print(negative_labels,neutral_labels,positive_labels)


plt.bar(index, negative_labels, width=bar_width, label = '1')
plt.bar(index + bar_width, neutral_labels, width=bar_width, label = '2')
plt.bar(index + 2 * bar_width, positive_labels, width=bar_width, label = '3')

plt.xlabel('Categories')
plt.ylabel('# results')
plt.title('Classification of labels versus country type')
plt.xticks(index + bar_width, categories)
plt.legend()


plt.show()

#basically the plot is plotting the list on the graph in the order that each list is presented. For instance, on the developing countries labels, the index 0 is plotted as blue in